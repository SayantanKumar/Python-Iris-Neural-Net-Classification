{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "nbpresent": {
     "id": "e67a8110-5dac-417e-8eb4-201f14389eac"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn import datasets as ds\n",
    "from scipy import optimize\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "nbpresent": {
     "id": "e7cedf0a-6acf-4573-aa87-a21dc87224bf"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(150, 1)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris = ds.load_iris() #Load the data set\n",
    "\n",
    "#Put the data and labels into an x and y matrix\n",
    "x = iris.data #(150,4)\n",
    "y = iris.target #(150,1)\n",
    "\n",
    "#Then normalize the data into a range between 0 & 1\n",
    "xM = x.max()\n",
    "print(y.max())\n",
    "x = x/x.max()\n",
    "y = y/y.max()\n",
    "y = np.reshape(y, (150,1))\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false,
    "nbpresent": {
     "id": "c06e5b9e-28e2-4c04-8ed5-8f3545e6f997"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "class NeuralNetwork(object):\n",
    "    def __init__(self):\n",
    "        np.random.seed(1) #Sets a random seed, this will help when debugging as all the random weights will be the same every time it is run\n",
    "        \n",
    "        #Neural Network Model\n",
    "        self.inputSize = 4 #4 Inputs, sepal length/width and petal length/width\n",
    "        self.hiddenSize = 5 #Rounded mean of input & output, we'll see how well it works\n",
    "        self.outputSize = 1 #1 Output to classify which flower it is\n",
    "        \n",
    "        #Create the weights randomly into a matrix of the same size as the number of nodes they are connected to \n",
    "        self.W1 = np.random.randn(self.inputSize, self.hiddenSize) #input -> hidden\n",
    "        self.W2 = np.random.randn(self.hiddenSize, self.outputSize) #hidden -> output\n",
    "        \n",
    "    #Predict function, you will be able to use this after the network is trained to predict it by passing an array for the sizes and the number used to normalize the training data\n",
    "    def predict(self, x, xM):\n",
    "        prediction = self.forwardProp((x/xM)) * 2 #Forward propagates the normalized array of data, then de-normalizes the output\n",
    "        if prediction < 0.5:\n",
    "            return \"Setosa\", prediction #Then prints out the name of the flower via comparitives, as well as the value for prediction\n",
    "        elif prediction < 1.5:\n",
    "            return \"Versicolor\", prediction\n",
    "        elif prediction < 2.5:\n",
    "            return \"Virginica\", prediction\n",
    "        else:\n",
    "            return \"ERROR\", prediction #If for whatever reason the value is wayyyyy out\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    def forwardProp(self, x):\n",
    "        #Propagrate all the data forwards through the network using sigmoid as our activation function\n",
    "        self.z2 = np.dot(x, self.W1) #Z's are the dot product of the output from the previous nodes and the weights\n",
    "        self.a2 = self.sigmoid(self.z2) #A and yHat are the z's but with the activation function applied\n",
    "        self.z3 = np.dot(self.a2, self.W2)\n",
    "        self.yHat = self.sigmoid(self.z3)\n",
    "        return self.yHat\n",
    "    \n",
    "    def sigmoid(self, z):\n",
    "        return 1/(1+np.exp(-z)) #Sigmoid equation, used for activation\n",
    "        \n",
    "    def costFunction(self, x, y):\n",
    "        self.yHat = self.forwardProp(x)\n",
    "        J = 0.5*sum((y-self.yHat)**2) #cost function to work out how wrong we were, the difference between the actual and predicted, squared then halved\n",
    "        return J\n",
    "    \n",
    "    def sigmoidDerived(self, z):\n",
    "        return ((np.exp(-z)) / ((1 + np.exp(-z))**2)) #Sigmoid but partially derived, this is used in gradient decent to alter the weights\n",
    "    \n",
    "\n",
    "    \n",
    "    def costFunctionDerived(self, X, y):\n",
    "        #The cost function but partially derived with respect to W and W2 for a given X and y, this is done \n",
    "        self.yHat = self.forwardProp(X)\n",
    "        \n",
    "        delta3 = np.multiply(-(y-self.yHat), self.sigmoidDerived(self.z3)) #The delta rule\n",
    "        dJdW2 = np.dot(self.a2.T, delta3)\n",
    "        \n",
    "        delta2 = np.dot(delta3, self.W2.T)*self.sigmoidDerived(self.z2)\n",
    "        dJdW1 = np.dot(X.T, delta2)  \n",
    "        \n",
    "        return dJdW1, dJdW2\n",
    "    \n",
    "    \n",
    "    \n",
    "    def getParams(self):\n",
    "        #Combines the 2 weights matrices into one \n",
    "        params = np.concatenate((self.W1.ravel(), self.W2.ravel()))\n",
    "        return params\n",
    "    \n",
    "    def setParams(self, params):\n",
    "        #Reset weights from the new single matrix back into 2 matrices\n",
    "        W1_start = 0\n",
    "        W1_end = self.hiddenSize * self.inputSize\n",
    "        self.W1 = np.reshape(params[W1_start:W1_end], (self.inputSize , self.hiddenSize))\n",
    "        W2_end = W1_end + self.hiddenSize*self.outputSize\n",
    "        self.W2 = np.reshape(params[W1_end:W2_end], (self.hiddenSize, self.outputSize))\n",
    "\n",
    "        \n",
    "        \n",
    "    def computeGradients(self, X, y):\n",
    "        dJdW1, dJdW2 = self.costFunctionDerived(X, y) #Work out the gradients for gradient decent\n",
    "        return np.concatenate((dJdW1.ravel(), dJdW2.ravel())) #Then return the 2 gradients as 1 matrix\n",
    "    \n",
    "    def callbackf(self, params):\n",
    "        self.setParams(params) #Reset the weight matrices\n",
    "        self.J.append(self.costFunction(self.X, self.Y)) #Add the cost of the current weights to the cost array\n",
    "        \n",
    "    def costFunctionWrapper(self, params, X, y):\n",
    "        self.setParams(params) #Reset the weight matrices\n",
    "        cost = self.costFunction(X, y) #Get the cost of the current weights\n",
    "        grad = self.computeGradients(X,y) #Get the gradient of the current weights\n",
    "        return cost, grad\n",
    "    \n",
    "    \n",
    "    def train(self, X, y):\n",
    "        #Create variables for local use\n",
    "        self.X = X\n",
    "        self.Y = y\n",
    "\n",
    "        #Create list to hold costs\n",
    "        self.J = []\n",
    "        \n",
    "        params0 = self.getParams() #Get the weights in one matrix for optimization\n",
    "\n",
    "        options = {'maxiter': 3500, 'disp' : False} #Set options for optimization - set disp to true to get more details when training\n",
    "        _res = optimize.minimize(self.costFunctionWrapper, params0, jac=True, method='BFGS', \\\n",
    "                                 args=(X, y), options=options, callback=self.callbackf) #And optimize\n",
    "        \n",
    "        self.setParams(_res.x) #Set the new weights from the outcome of the optimization\n",
    "        #self.optimizationResults = _res\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false,
    "nbpresent": {
     "id": "443eec95-521a-44ed-86a3-bade744e2264"
    }
   },
   "outputs": [],
   "source": [
    "net = NeuralNetwork()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false,
    "nbpresent": {
     "id": "e8fc4622-41ec-4cb9-9dda-7aabaf5d3ea9"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost Before: 0.17220415367786837\n",
      "Cost After: 0.17208910217798218\n",
      "Cost difference: 0.0001150514998861929\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tom_b\\Anaconda3\\lib\\site-packages\\ipykernel\\__main__.py:46: RuntimeWarning: overflow encountered in square\n",
      "C:\\Users\\tom_b\\Anaconda3\\lib\\site-packages\\ipykernel\\__main__.py:38: RuntimeWarning: overflow encountered in exp\n",
      "C:\\Users\\tom_b\\Anaconda3\\lib\\site-packages\\ipykernel\\__main__.py:46: RuntimeWarning: overflow encountered in exp\n",
      "C:\\Users\\tom_b\\Anaconda3\\lib\\site-packages\\ipykernel\\__main__.py:46: RuntimeWarning: invalid value encountered in true_divide\n",
      "C:\\Users\\tom_b\\Anaconda3\\lib\\site-packages\\ipykernel\\__main__.py:38: RuntimeWarning: overflow encountered in exp\n",
      "C:\\Users\\tom_b\\Anaconda3\\lib\\site-packages\\ipykernel\\__main__.py:46: RuntimeWarning: overflow encountered in exp\n",
      "C:\\Users\\tom_b\\Anaconda3\\lib\\site-packages\\ipykernel\\__main__.py:46: RuntimeWarning: overflow encountered in square\n",
      "C:\\Users\\tom_b\\Anaconda3\\lib\\site-packages\\ipykernel\\__main__.py:46: RuntimeWarning: invalid value encountered in true_divide\n"
     ]
    }
   ],
   "source": [
    "costBefore = float(net.costFunction(x,y)[0])\n",
    "net.train(x, y)\n",
    "costAfter = float(net.costFunction(x,y)[0])\n",
    "\n",
    "print(\"Cost Before: \" + str(costBefore))\n",
    "print(\"Cost After: \" + str(costAfter))\n",
    "print(\"Cost difference: \" + str(costBefore - costAfter))\n",
    "\n",
    "#Uncomment to show graph\n",
    "#plt.plot(net.J)\n",
    "#plt.grid(1)\n",
    "#plt.xlabel('Iterations')\n",
    "#plt.ylabel('Cost')\n",
    "#plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false,
    "nbpresent": {
     "id": "7b57544e-17c8-438d-8e2e-65c66a4765e0"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Setosa', array([  7.72861070e-08]))"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.predict([6.7,5.2,2.5,1.6], xM) #Demo - some sizes in a 1:4 array, as well as the xM variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "nbpresent": {
     "id": "1b70a1dd-fbd4-4192-a375-4834433f53b4"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "nbpresent": {
   "slides": {
    "a4fb8142-7008-44a3-b4a2-324c96965126": {
     "id": "a4fb8142-7008-44a3-b4a2-324c96965126",
     "prev": null,
     "regions": {
      "58e6ecc0-842c-4295-8209-2f3d0645804d": {
       "attrs": {
        "height": 1,
        "width": 1,
        "x": -0.006072874493927126,
        "y": 0.00599790073474284
       },
       "id": "58e6ecc0-842c-4295-8209-2f3d0645804d"
      },
      "72c3aa58-a5c8-487a-b031-a4a3fc8517e2": {
       "attrs": {
        "height": 0.11983805668016205,
        "width": 0.8,
        "x": 0.01835357624831312,
        "y": 0.1851701904333483
       },
       "id": "72c3aa58-a5c8-487a-b031-a4a3fc8517e2"
      }
     }
    }
   },
   "themes": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
